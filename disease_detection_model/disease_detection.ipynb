{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "g-DdRuc_W5Md"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " import kagglehub\n",
        " # Download latest version\n",
        " path = kagglehub.dataset_download(\"emmarex/plantdisease\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gofvjt7aW7Ze",
        "outputId": "eea4d7f4-33bf-4567-8dbc-df1e13d5d0b2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/emmarex/plantdisease?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 658M/658M [00:05<00:00, 116MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir=os.path.join(path, \"PlantVillage\" )"
      ],
      "metadata": {
        "id": "BIDVx5f4XIIk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Image preprocessing parameters\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Data augmentation (optional but recommended)\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalize pixel values\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2 # 20% for validation\n",
        ")\n",
        "\n",
        "# Create training data generator\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical', # Assuming multi-class classification\n",
        "    subset='training',\n",
        "    shuffle=True,\n",
        "    seed=42  # for reproducibility\n",
        ")\n",
        "\n",
        "# Create validation data generator\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "id": "VegSUa-Jfxpy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a47963f8-adbc-4383-c376-0e03a6a4a406"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 16516 images belonging to 15 classes.\n",
            "Found 4122 images belonging to 15 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "disease_types=train_generator.class_indices.keys()"
      ],
      "metadata": {
        "id": "RDiSi3Zbyfjf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2  # Example transfer learning model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load the pre-trained model (excluding the top classification layer)\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "# Add custom classification layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)  # Adjust units as needed\n",
        "predictions = Dense(len(disease_types), activation='softmax')(x)  # Output layer\n",
        "\n",
        "# Create the final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the base model layers (optional, but often improves initial training)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['f1_score'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iux6Ei4O8Zni",
        "outputId": "620d436a-02a5-4ec2-b03d-01918d328085"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m517/517\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 504ms/step - f1_score: 0.5473 - loss: 1.2567 - val_f1_score: 0.8169 - val_loss: 0.5189\n",
            "Epoch 2/10\n",
            "\u001b[1m517/517\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 475ms/step - f1_score: 0.8287 - loss: 0.4682 - val_f1_score: 0.8424 - val_loss: 0.4304\n",
            "Epoch 3/10\n",
            "\u001b[1m517/517\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 476ms/step - f1_score: 0.8617 - loss: 0.3750 - val_f1_score: 0.8662 - val_loss: 0.3617\n",
            "Epoch 4/10\n",
            "\u001b[1m517/517\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 478ms/step - f1_score: 0.8736 - loss: 0.3388 - val_f1_score: 0.8631 - val_loss: 0.3484\n",
            "Epoch 5/10\n",
            "\u001b[1m517/517\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 471ms/step - f1_score: 0.8908 - loss: 0.3008 - val_f1_score: 0.8788 - val_loss: 0.3202\n",
            "Epoch 6/10\n",
            "\u001b[1m517/517\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 538ms/step - f1_score: 0.8924 - loss: 0.2874 - val_f1_score: 0.8777 - val_loss: 0.3287\n",
            "Epoch 7/10\n",
            "\u001b[1m517/517\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 473ms/step - f1_score: 0.9049 - loss: 0.2720 - val_f1_score: 0.8993 - val_loss: 0.2821\n",
            "Epoch 8/10\n",
            "\u001b[1m517/517\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 479ms/step - f1_score: 0.9052 - loss: 0.2542 - val_f1_score: 0.8941 - val_loss: 0.2782\n",
            "Epoch 9/10\n",
            "\u001b[1m517/517\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 487ms/step - f1_score: 0.9149 - loss: 0.2360 - val_f1_score: 0.8927 - val_loss: 0.2867\n",
            "Epoch 10/10\n",
            "\u001b[1m517/517\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 471ms/step - f1_score: 0.9135 - loss: 0.2325 - val_f1_score: 0.8976 - val_loss: 0.2842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: test the data with model.eval and give me the f1 score and the loss of testing\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(validation_generator)\n",
        "\n",
        "# Get predictions\n",
        "predictions = model.predict(validation_generator)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get true classes\n",
        "true_classes = validation_generator.classes\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(true_classes, predicted_classes, average='weighted')  # Use 'weighted' for multi-class\n",
        "\n",
        "print(f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhRIQaTX-MBM",
        "outputId": "9f783843-192d-44e9-df74-debe8c228ff7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 380ms/step - f1_score: 0.5271 - loss: 0.2449\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 423ms/step\n",
            "F1 Score: 0.8962710340535448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('disease_detection.h5')"
      ],
      "metadata": {
        "id": "y_qNiq-JE6Nr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba1b3bdc-a212-42c3-b145-8f5463d28734"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    }
  ]
}